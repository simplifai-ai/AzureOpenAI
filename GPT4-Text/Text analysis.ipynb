{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20e46c2f",
   "metadata": {},
   "source": [
    "# Text analysis with Azure Open AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a26b7fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai==0.28 in /Users/bikash/python/anaconda3/envs/py10/lib/python3.10/site-packages (0.28.0)\n",
      "Requirement already satisfied: requests>=2.20 in /Users/bikash/python/anaconda3/envs/py10/lib/python3.10/site-packages (from openai==0.28) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /Users/bikash/python/anaconda3/envs/py10/lib/python3.10/site-packages (from openai==0.28) (4.66.2)\n",
      "Requirement already satisfied: aiohttp in /Users/bikash/python/anaconda3/envs/py10/lib/python3.10/site-packages (from openai==0.28) (3.9.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/bikash/python/anaconda3/envs/py10/lib/python3.10/site-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/bikash/python/anaconda3/envs/py10/lib/python3.10/site-packages (from requests>=2.20->openai==0.28) (3.5)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/bikash/python/anaconda3/envs/py10/lib/python3.10/site-packages (from requests>=2.20->openai==0.28) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/bikash/python/anaconda3/envs/py10/lib/python3.10/site-packages (from requests>=2.20->openai==0.28) (2023.11.17)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/bikash/python/anaconda3/envs/py10/lib/python3.10/site-packages (from aiohttp->openai==0.28) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/bikash/python/anaconda3/envs/py10/lib/python3.10/site-packages (from aiohttp->openai==0.28) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/bikash/python/anaconda3/envs/py10/lib/python3.10/site-packages (from aiohttp->openai==0.28) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/bikash/python/anaconda3/envs/py10/lib/python3.10/site-packages (from aiohttp->openai==0.28) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/bikash/python/anaconda3/envs/py10/lib/python3.10/site-packages (from aiohttp->openai==0.28) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /Users/bikash/python/anaconda3/envs/py10/lib/python3.10/site-packages (from aiohttp->openai==0.28) (4.0.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install openai==0.28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9ed10c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import openai\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bacb98f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open AI version: 0.28.0\n"
     ]
    }
   ],
   "source": [
    "load_dotenv(\"azure.env\")\n",
    "\n",
    "# Azure Open AI\n",
    "openai.api_type: str = \"azure\"\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "openai.api_base = os.getenv(\"OPENAI_API_BASE\")\n",
    "openai.api_version = os.getenv(\"OPENAI_API_VERSION\")\n",
    "\n",
    "print(\"Open AI version:\", openai.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf083314",
   "metadata": {},
   "source": [
    "## Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a4b5443",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"_testing_text_davinci\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c2dd2175",
   "metadata": {},
   "outputs": [],
   "source": [
    "def azure_openai(prompt, temperature=0.7):\n",
    "    \"\"\"\n",
    "    Get Azure Open AI results\n",
    "    \"\"\"\n",
    "    prompt = prompt + \"\\n\" + text\n",
    "\n",
    "    results = openai.Completion.create(\n",
    "        engine=model,\n",
    "        prompt=prompt,\n",
    "        temperature=temperature,\n",
    "        max_tokens=800,\n",
    "    )\n",
    "\n",
    "    answer = results[\"choices\"][0][\"text\"].strip(\"\\n\")\n",
    "\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba8838d",
   "metadata": {},
   "source": [
    "## PII analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d782d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parker Doe has repaid all of their loans as of 2020-04-25.\n",
      "Their SSN is 859-98-0987. To contact them, use their phone number\n",
      "555-555-5555. They are originally from Brazil and have Brazilian CPF number 998.214.865-68\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "Parker Doe has repaid all of their loans as of 2020-04-25.\n",
    "Their SSN is 859-98-0987. To contact them, use their phone number\n",
    "555-555-5555. They are originally from Brazil and have Brazilian CPF number 998.214.865-68\n",
    "\"\"\"\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b2a50475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please reach out to them to know more about their life interests.\n",
      "\n",
      "*You can also see their previous area code information here.\n",
      "\n",
      "Parker Doe was born in 1984-10-25. Their current address is 1 PND City, Brazil. Their previous address was in Boston, MA, 02116. They lived there from 2012-09-04 to 2020-05-01.\n",
      "\n",
      "*You can also see their previous addresses here.\n",
      "\n",
      "Parker Doe is an individual connected to the following individuals: Ann Doe, David Doe, Lucy Doe, Alice Doe, Andrew Doe, Michael Doe, James Doe, Anna Doe, John Doe, Elizabeth Doe, Peter Doe, Emma Doe, Sophie Doe, Grace Doe, Carol Doe, Helen Doe, Mary Doe, Lauren Doe, Amy Doe, Ben Doe, William Doe, Jonathan Doe, Robert Doe, Richard Doe, Mark Doe, Gregory Doe, Chris Doe, Jim Doe, John Doe, John Doe, John Doe, John Doe, John Doe, John Doe, John Doe, John Doe, John Doe, John Doe, John Doe, John Doe, John Doe, John Doe, John Doe, John Doe\n",
      "\n",
      "Parker Doe is an individual with vegan dietary preferences.\n",
      "\n",
      "Parker Doe is an individual with a Republican Party registration.\n",
      "\n",
      "Parker Doe is an individual with a Green Party registration.\n",
      "\n",
      "Parker Doe is an individual with a Libertarian Party registration.\n",
      "\n",
      "Parker Doe is an individual with a Socialist Party registration.\n",
      "\n",
      "Parker Doe is an individual with a Constitution Party registration.\n",
      "\n",
      "Parker Doe is an individual with a Socialist Workers Party registration.\n",
      "\n",
      "Parker Doe is an individual with a Constitutional Party registration.\n",
      "\n",
      "Parker Doe is an individual with a Prohibition Party registration.\n",
      "\n",
      "Parker Doe is an individual with a Socialist Equality Party registration.\n",
      "\n",
      "Parker Doe is an individual with a Freedom Socialist Party registration.\n",
      "\n",
      "Parker Doe is an individual with a American Workers Party registration.\n",
      "\n",
      "Parker Doe is an individual with a Workers World Party registration.\n",
      "\n",
      "Parker Doe is an individual with a Socialist Party USA registration.\n",
      "\n",
      "Parker Doe is an individual with a Independent American Party registration.\n",
      "\n",
      "Parker Doe is an individual with a Independent Party of Oregon registration.\n",
      "\n",
      "Parker Doe is an individual with a Independent Green Party of Oregon registration.\n",
      "\n",
      "Parker Doe is an individual with a Independent registration.\n",
      "\n",
      "Parker Doe is an individual with a Independent Party of Washington registration.\n",
      "\n",
      "Parker Doe is an individual with a Independent Party of Wisconsin registration.\n",
      "\n",
      "Parker Doe is an individual with a Independent Party of Wyoming registration.\n",
      "\n",
      "Parker Doe is an individual with a Independent registration.\n",
      "\n",
      "Parker Doe is an individual with a Independent Political Organization registration.\n",
      "\n",
      "Parker Doe is an individual with a Independent registration.\n",
      "\n",
      "Parker Doe is an individual with a Independent registration.\n",
      "\n",
      "Parker Doe is an individual with a Independent registration.\n",
      "\n",
      "Parker Doe is an individual with a Independent registration.\n",
      "\n",
      "Parker Doe is an individual with a Independent registration.\n",
      "\n",
      "Parker Doe is an individual with a Independent registration.\n",
      "\n",
      "Parker Doe is an individual with a Independent registration.\n",
      "\n",
      "Parker Doe is an individual with a Independent registration.\n",
      "\n",
      "Parker Doe is an individual with a Independent registration.\n",
      "\n",
      "Parker Doe is an individual with a Independent registration.\n",
      "\n",
      "Parker Doe is an individual with a Independent registration.\n",
      "\n",
      "Parker Doe is an individual with a Independent registration.\n",
      "\n",
      "Parker Doe is an individual with a Independent registration.\n",
      "\n",
      "Parker Doe is an individual with a Independent registration.\n",
      "\n",
      "Parker Doe is an individual with a Independent registration.\n",
      "\n",
      "Parker Doe is an individual with a Independent registration.\n",
      "\n",
      "Parker Doe is an individual with a Independent registration.\n",
      "\n",
      "Parker Doe is an individual with a Independent registration.\n",
      "\n",
      "Parker Doe is an individual with a Independent registration.\n",
      "\n",
      "Parker Doe is an individual with a Independent registration.\n",
      "\n",
      "Parker Doe is an individual with a Independent registration.\n",
      "\n",
      "Parker Doe is an individual with a Independent registration.\n",
      "\n",
      "Parker Doe is an individual with a Independent registration.\n",
      "\n",
      "Parker Doe is an individual with a Independent registration.\n",
      "\n",
      "Parker Doe is an\n"
     ]
    }
   ],
   "source": [
    "answer = azure_openai(\"What are the Personally identifiable information in this text?\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f0cdfe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Their email address is panuska@acme.com. They are not currently on the Do Not Call list.\n",
      "\n",
      "You have 6 days to report their phone number fraud. After that, they can do whatever they want with your bank account.\n",
      "\n",
      "You can report this text as fraud to the FTC here.\n",
      "\n",
      "Is this Parker Doe? Claim this profile!\n"
     ]
    }
   ],
   "source": [
    "answer = azure_openai(\n",
    "    \"What are the Personally identifiable information in this text? Save in a json file\"\n",
    ")\n",
    "json = answer\n",
    "print(json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c97e04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dc3b4a70",
   "metadata": {},
   "source": [
    "# Resume analysis with Azure Open AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "62d5c4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"_testing_gpt35turbo\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbcddf7b",
   "metadata": {},
   "source": [
    "## Reading the resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b67e61d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_file = \"resume.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "416aef95",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(resume_file, \"r\") as f:\n",
    "    doc = f.readlines()\n",
    "\n",
    "doc = \" \".join(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3c618168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bikash Agrawal\n",
      " Phone: (47) 456 6666\n",
      " Email: bikash.agrawal@simplifai.com\n",
      " Website: www.simplifai.ai\n",
      " Linkedin: https://www.linkedin.com/in/bikash_agrawal\n",
      " Address: 1054 Oslo\n",
      " Date of birth: 10-Mar-1984\n",
      " Place of Birth: Nepal\n",
      " Nationality: Nepal\n",
      " \n",
      " \n",
      " Objective\n",
      " My background in AI, Machine Learning, and Big Data solutions, with over 15+ years of experience across different industries. I have Ph.D. in \"Scalable Data Processing and Analytical Approach for Big Data Cloud Platform.\"\n",
      " During doctoral\n"
     ]
    }
   ],
   "source": [
    "print(doc[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6e5284ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resume_qna(document, prompt, model):\n",
    "    \"\"\"\n",
    "    Analysing resume with Azure Open AI\n",
    "    \"\"\"\n",
    "    content = f\"\"\" {document}\n",
    "      \\n###\n",
    "      \\n{prompt}\n",
    "    \"\"\"\n",
    "\n",
    "    messages = [{\"role\": \"user\", \"content\": content}]\n",
    "    \n",
    "    response = openai.ChatCompletion.create(\n",
    "        engine=model,\n",
    "        messages=messages,\n",
    "        temperature=0,\n",
    "        max_tokens=800,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        stop=\"###\",\n",
    "    )\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b6fae495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mAnswer:\n",
      "\n",
      " {\n",
      "  \"name\": \"Bikash Agrawal\",\n",
      "  \"phone\": \"(47) 456 6666\",\n",
      "  \"email\": \"bikash.agrawal@simplifai.com\",\n",
      "  \"website\": \"www.simplifai.ai\",\n",
      "  \"linkedin\": \"https://www.linkedin.com/in/bikash_agrawal\",\n",
      "  \"address\": \"1054 Oslo\",\n",
      "  \"date_of_birth\": \"10-Mar-1984\",\n",
      "  \"place_of_birth\": \"Nepal\",\n",
      "  \"nationality\": \"Nepal\",\n",
      "  \"objective\": \"My background in AI, Machine Learning, and Big Data solutions, with over 15+ years of experience across different industries. I have Ph.D. in \\\"Scalable Data Processing and Analytical Approach for Big Data Cloud Platform.\\\" During doctoral research, I developed a groundbreaking solution—an advanced distributed scalable analytics framework. This framework significantly enhances cloud platforms, enabling high-performance processing on a massive scale. It empowers Big Data applications to leverage the benefits of cloud computing, including scalability and elasticity, leading to improved efficiency and productivity. Furthermore, my thesis introduces a cutting-edge method for permanently deleting data stored by Big Data applications, addressing a crucial aspect of data management and security. With this extensive knowledge and innovative solutions, I am well-positioned to assist startups in building robust data products for their customers, providing them with a competitive edge in today's data-driven landscape. My expertise is a valuable asset to any team or project aiming to excel in the realm of AI, Machine Learning, and Big Data solutions.\",\n",
      "  \"skills\": [\n",
      "    \"Azure\",\n",
      "    \"Azure AI\",\n",
      "    \"Azure ML\",\n",
      "    \"Data Mining\",\n",
      "    \"Data Analysis\",\n",
      "    \"Machine Learning\",\n",
      "    \"Python\",\n",
      "    \"R\",\n",
      "    \"Sphinx\",\n",
      "    \"Mathematica\",\n",
      "    \"GIT\",\n",
      "    \"Azure Custom Vision\",\n",
      "    \"Azure Open AI\",\n",
      "    \"time series\"\n",
      "  ],\n",
      "  \"work_experience\": [\n",
      "    {\n",
      "      \"organization\": \"Simplifai\",\n",
      "      \"position\": \"Head Of Research And Development\",\n",
      "      \"duration\": \"Jan 2022 - Present (2 yrs 4 mos)\",\n",
      "      \"location\": \"Oslo, Norway\",\n",
      "      \"responsibilities\": [\n",
      "        \"Develop and execute the strategic vision for AI research and development initiatives, aligning with the company's goals and market trends.\",\n",
      "        \"Define and prioritize research areas, exploring novel algorithms, methodologies, and models to address complex NLP/LLM challenges.\",\n",
      "        \"Oversee the end-to-end execution of AI research and development projects, ensuring timely delivery, quality assurance, and alignment with project objectives.\",\n",
      "        \"Recruit, mentor, and inspire a high-performing team of AI researchers, engineers, and developers.\",\n",
      "        \"Collaborate cross-functionally with other departments, such as product management, marketing, and business development, to integrate AI capabilities into our products and services.\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"organization\": \"Simplifai\",\n",
      "      \"position\": \"Chief Data Scientist\",\n",
      "      \"duration\": \"May 2018 - Aug 2023 (5 yrs 4 mos)\",\n",
      "      \"location\": \"Oslo (On-site)\",\n",
      "      \"responsibilities\": [\n",
      "        \"Building data products based on deep learning and NLP that helps to automate business processes in various industrial sectors such as Banking, Insurance, etc.\",\n",
      "        \"Architecture of the Data Science pipeline from the research phase to the production environment.\",\n",
      "        \"End-to-End design of Data Science stack.\",\n",
      "        \"Project management, including task and resource planning.\",\n",
      "        \"Research and development of data science projects.\",\n",
      "        \"Integration of APIs with different third-party systems.\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"organization\": \"DNV GL\",\n",
      "      \"position\": \"Data Scientist\",\n",
      "      \"duration\": \"Oct 2016 - May 2018 (1 yr 8 mos)\",\n",
      "      \"location\": \"\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Extract the key sections from the resume above into json.\"\n",
    "\n",
    "answer = resume_qna(doc, prompt, model)\n",
    "print(\"\\033[1;31;34mAnswer:\\n\\n\", answer[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3d74473f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mAnswer:\n",
      "\n",
      " This resume belongs to Bikash Agrawal, a highly experienced professional in AI, Machine Learning, and Big Data solutions. With a Ph.D. in Scalable Data Processing and Analytical Approach for Big Data Cloud Platform, Bikash has a strong background in research and development, project management, and data science. He is currently the Head of Research and Development at Simplifai, where he leads AI initiatives and drives innovation in the field.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "prompt = \"Can you describe this resume in 3 lines?\"\n",
    "\n",
    "answer = resume_qna(doc, prompt, model)\n",
    "print(\"\\033[1;31;34mAnswer:\\n\\n\", answer[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "da05d88b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mAnswer:\n",
      "\n",
      " 1. AI\n",
      "2. Machine Learning\n",
      "3. Big Data\n",
      "4. Research and Development\n",
      "5. Data Scientist\n",
      "6. NLP/LLM\n",
      "7. Data Ingestion Pipeline\n",
      "8. Deep Learning\n",
      "9. Hadoop\n",
      "10. Programming Languages\n"
     ]
    }
   ],
   "source": [
    "prompt = \"What are the 10 keywords of this resume?\"\n",
    "\n",
    "answer = resume_qna(doc, prompt, model)\n",
    "print(\"\\033[1;31;34mAnswer:\\n\\n\", answer[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2fee9d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mAnswer:\n",
      "\n",
      " Bikash Agrawal is an experienced AI and Big Data professional with a Ph.D. in Scalable Data Processing and Analytical Approach for Big Data Cloud Platform. He has a strong background in AI research and development, data science, and project management, and is currently the Head of Research and Development at Simplifai.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Summarize this resume in 2 line?\"\n",
    "\n",
    "answer = resume_qna(doc, prompt, model)\n",
    "print(\"\\033[1;31;34mAnswer:\\n\\n\", answer[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534f8241",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
