{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20e46c2f",
   "metadata": {},
   "source": [
    "# Text analysis with Azure Open AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a26b7fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai==0.28\n",
      "  Using cached openai-0.28.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: requests>=2.20 in /Users/bikash/python/anaconda3/envs/py10/lib/python3.10/site-packages (from openai==0.28) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /Users/bikash/python/anaconda3/envs/py10/lib/python3.10/site-packages (from openai==0.28) (4.66.2)\n",
      "Requirement already satisfied: aiohttp in /Users/bikash/python/anaconda3/envs/py10/lib/python3.10/site-packages (from openai==0.28) (3.9.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/bikash/python/anaconda3/envs/py10/lib/python3.10/site-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/bikash/python/anaconda3/envs/py10/lib/python3.10/site-packages (from requests>=2.20->openai==0.28) (3.5)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/bikash/python/anaconda3/envs/py10/lib/python3.10/site-packages (from requests>=2.20->openai==0.28) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/bikash/python/anaconda3/envs/py10/lib/python3.10/site-packages (from requests>=2.20->openai==0.28) (2023.11.17)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/bikash/python/anaconda3/envs/py10/lib/python3.10/site-packages (from aiohttp->openai==0.28) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/bikash/python/anaconda3/envs/py10/lib/python3.10/site-packages (from aiohttp->openai==0.28) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/bikash/python/anaconda3/envs/py10/lib/python3.10/site-packages (from aiohttp->openai==0.28) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/bikash/python/anaconda3/envs/py10/lib/python3.10/site-packages (from aiohttp->openai==0.28) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/bikash/python/anaconda3/envs/py10/lib/python3.10/site-packages (from aiohttp->openai==0.28) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /Users/bikash/python/anaconda3/envs/py10/lib/python3.10/site-packages (from aiohttp->openai==0.28) (4.0.3)\n",
      "Using cached openai-0.28.0-py3-none-any.whl (76 kB)\n",
      "Installing collected packages: openai\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 1.12.0\n",
      "    Uninstalling openai-1.12.0:\n",
      "      Successfully uninstalled openai-1.12.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain-openai 0.0.5 requires openai<2.0.0,>=1.10.0, but you have openai 0.28.0 which is incompatible.\n",
      "llama-index-core 0.10.29 requires openai>=1.1.0, but you have openai 0.28.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed openai-0.28.0\n"
     ]
    }
   ],
   "source": [
    "!pip install openai==0.28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a9ed10c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import openai\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bacb98f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open AI version: 0.28.0\n"
     ]
    }
   ],
   "source": [
    "load_dotenv(\"azure.env\")\n",
    "\n",
    "# Azure Open AI\n",
    "openai.api_type: str = \"azure\"\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "openai.api_base = os.getenv(\"OPENAI_API_BASE\")\n",
    "openai.api_version = os.getenv(\"OPENAI_API_VERSION\")\n",
    "\n",
    "print(\"Open AI version:\", openai.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf083314",
   "metadata": {},
   "source": [
    "## Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1a4b5443",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"_testing_text_davinci\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c2dd2175",
   "metadata": {},
   "outputs": [],
   "source": [
    "def azure_openai(prompt, temperature=0.6):\n",
    "    \"\"\"\n",
    "    Get Azure Open AI results\n",
    "    \"\"\"\n",
    "    prompt = prompt + \"\\n\" + text\n",
    "\n",
    "    results = openai.Completion.create(\n",
    "        engine=model,\n",
    "        prompt=prompt,\n",
    "        temperature=temperature,\n",
    "        max_tokens=800,\n",
    "    )\n",
    "\n",
    "    answer = results[\"choices\"][0][\"text\"].strip(\"\\n\")\n",
    "\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba8838d",
   "metadata": {},
   "source": [
    "## PII analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5d782d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parker Doe has repaid all of their loans as of 2020-04-25.\n",
      "Their SSN is 859-98-0987. To contact them, use their phone number\n",
      "555-555-5555. They are originally from Brazil and have Brazilian CPF number 998.214.865-68\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "Parker Doe has repaid all of their loans as of 2020-04-25.\n",
    "Their SSN is 859-98-0987. To contact them, use their phone number\n",
    "555-555-5555. They are originally from Brazil and have Brazilian CPF number 998.214.865-68\n",
    "\"\"\"\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b2a50475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "and they are not registered with the U.S. Department of Education.\n",
      "\n",
      "Parker Doe holds the following federal student loans: 1 loans\n",
      "\n",
      "- Direct Subsidized Loans\n",
      "\n",
      "Direct Subsidized Loans\n",
      "\n",
      "Direct Subsidized Loans are available to undergraduate students who demonstrate financial need. The U.S. Department of Education pays the interest on the loan while the student is enrolled in college at least half-time. Once the studentâ€™s enrollment drops below half-time status, the interest begins to accrue on the loan. If the loan is not repaid while the student is in school, interest will accrue and be capitalized (that is, the interest will be added to the principal amount of the loan and the borrower will then owe interest on the higher, combined amount).\n",
      "\n",
      "Direct Subsidized Loans are limited to the cost of attendance minus any other financial aid received by the student. The maximum amount a student can borrow is $5,500 for the first year of undergraduate study; up to $6,500 for the second year; and up to $7,500 for the third year. The maximum amount a student can borrow in Direct Subsidized Loans for undergraduate study is $23,000. The interest rate for Direct Subsidized Loans first disbursed on or after July 1, 2012, and before July 1, 2014, is 3.86 percent. The interest rate for Direct Subsidized Loans first disbursed on or after July 1, 2014, and before July 1, 2015, is 4.66 percent.\n",
      "\n",
      "The interest rate for Direct Subsidized Loans first disbursed on or after July 1, 2015, and before July 1, 2016, is 4.29 percent. The interest rate for Direct Subsidized Loans first disbursed on or after July 1, 2016, and before July 1, 2017, is 3.76 percent. The interest rate for Direct Subsidized Loans first disbursed on or after July 1, 2017, and before July 1, 2018, is 3.76 percent. The interest rate for Direct Subsidized Loans first disbursed on or after July 1, 2018, and before July 1, 2019, is 4.53 percent. The interest rate for Direct Subsidized Loans first disbursed on or after July 1, 2019, and before July 1, 2020, is 4.53 percent.\n",
      "\n",
      "The interest rate for Direct Subsidized Loans first disbursed on or after July 1, 2020, and before July 1, 2021, is 2.75 percent. The interest rate for Direct Subsidized Loans first disbursed on or after July 1, 2021, and before July 1, 2022, is 2.75 percent. The interest rate for Direct Subsidized Loans first disbursed on or after July 1, 2022, and before July 1, 2023, is 2.75 percent. The interest rate for Direct Subsidized Loans first disbursed on or after July 1, 2023, and before July 1, 2024, is 2.75 percent. The interest rate for Direct Subsidized Loans first disbursed on or after July 1, 2024, and before July 1, 2025, is 2.75 percent.\n",
      "\n",
      "The interest rate for Direct Subsidized Loans first disbursed on or after July 1, 2025, and before July 1, 2026, is 2.75 percent. The interest rate for Direct Subsidized Loans first disbursed on or after July 1, 2026, and before July 1, 2027, is 2.75 percent.\n"
     ]
    }
   ],
   "source": [
    "answer = azure_openai(\"What are the Personally identifiable information in this text?\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1f0cdfe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "and their current address is 55-7-1-1-1-2-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-1-\n"
     ]
    }
   ],
   "source": [
    "answer = azure_openai(\n",
    "    \"What are the Personally identifiable information in this text? Save in a json file\"\n",
    ")\n",
    "json = answer\n",
    "print(json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c97e04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dc3b4a70",
   "metadata": {},
   "source": [
    "# Resume analysis with Azure Open AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "62d5c4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"_testing_gpt35turbo\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbcddf7b",
   "metadata": {},
   "source": [
    "## Reading the resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b67e61d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_file = \"resume.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "416aef95",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(resume_file, \"r\") as f:\n",
    "    doc = f.readlines()\n",
    "\n",
    "doc = \" \".join(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3c618168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bikash Agrawal\n",
      " Phone: (47) 456 6666\n",
      " Email: bikash.agrawal@simplifai.com\n",
      " Website: www.simplifai.ai\n",
      " Linkedin: https://www.linkedin.com/in/bikash_agrawal\n",
      " Address: 1054 Oslo\n",
      " Date of birth: 10-Mar-1984\n",
      " Place of Birth: Nepal\n",
      " Nationality: Nepal\n",
      " \n",
      " \n",
      " Objective\n",
      " My background in AI, Machine Learning, and Big Data solutions, with over 15+ years of experience across different industries. I have Ph.D. in \"Scalable Data Processing and Analytical Approach for Big Data Cloud Platform.\"\n",
      " During doctoral\n"
     ]
    }
   ],
   "source": [
    "print(doc[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6e5284ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resume_qna(document, prompt, model):\n",
    "    \"\"\"\n",
    "    Analysing resume with Azure Open AI\n",
    "    \"\"\"\n",
    "    content = f\"\"\" {document}\n",
    "      \\n###\n",
    "      \\n{prompt}\n",
    "    \"\"\"\n",
    "\n",
    "    messages = [{\"role\": \"user\", \"content\": content}]\n",
    "    \n",
    "    response = openai.ChatCompletion.create(\n",
    "        engine=model,\n",
    "        messages=messages,\n",
    "        temperature=0,\n",
    "        max_tokens=800,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        stop=\"###\",\n",
    "    )\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b6fae495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mAnswer:\n",
      "\n",
      " {\n",
      "  \"name\": \"Bikash Agrawal\",\n",
      "  \"phone\": \"(47) 456 6666\",\n",
      "  \"email\": \"bikash.agrawal@simplifai.com\",\n",
      "  \"website\": \"www.simplifai.ai\",\n",
      "  \"linkedin\": \"https://www.linkedin.com/in/bikash_agrawal\",\n",
      "  \"address\": \"1054 Oslo\",\n",
      "  \"date_of_birth\": \"10-Mar-1984\",\n",
      "  \"place_of_birth\": \"Nepal\",\n",
      "  \"nationality\": \"Nepal\",\n",
      "  \"objective\": \"My background in AI, Machine Learning, and Big Data solutions, with over 15+ years of experience across different industries. I have Ph.D. in \\\"Scalable Data Processing and Analytical Approach for Big Data Cloud Platform.\\\" During doctoral research, I developed a groundbreaking solutionâ€”an advanced distributed scalable analytics framework. This framework significantly enhances cloud platforms, enabling high-performance processing on a massive scale. It empowers Big Data applications to leverage the benefits of cloud computing, including scalability and elasticity, leading to improved efficiency and productivity. Furthermore, my thesis introduces a cutting-edge method for permanently deleting data stored by Big Data applications, addressing a crucial aspect of data management and security. With this extensive knowledge and innovative solutions, I am well-positioned to assist startups in building robust data products for their customers, providing them with a competitive edge in today's data-driven landscape. My expertise is a valuable asset to any team or project aiming to excel in the realm of AI, Machine Learning, and Big Data solutions.\",\n",
      "  \"skills\": [\n",
      "    \"Azure\",\n",
      "    \"Azure AI\",\n",
      "    \"Azure ML\",\n",
      "    \"Data Mining\",\n",
      "    \"Data Analysis\",\n",
      "    \"Machine Learning\",\n",
      "    \"Python\",\n",
      "    \"R\",\n",
      "    \"Sphinx\",\n",
      "    \"Mathematica\",\n",
      "    \"GIT\",\n",
      "    \"Azure Custom Vision\",\n",
      "    \"Azure Open AI\",\n",
      "    \"time series\"\n",
      "  ],\n",
      "  \"work_experience\": [\n",
      "    {\n",
      "      \"organization\": \"Simplifai\",\n",
      "      \"position\": \"Head Of Research And Development\",\n",
      "      \"duration\": \"Jan 2022 - Present (2 yrs 4 mos)\",\n",
      "      \"location\": \"Oslo, Norway\",\n",
      "      \"responsibilities\": [\n",
      "        \"Develop and execute the strategic vision for AI research and development initiatives, aligning with the company's goals and market trends.\",\n",
      "        \"Define and prioritize research areas, exploring novel algorithms, methodologies, and models to address complex NLP/LLM challenges.\",\n",
      "        \"Oversee the end-to-end execution of AI research and development projects, ensuring timely delivery, quality assurance, and alignment with project objectives.\",\n",
      "        \"Recruit, mentor, and inspire a high-performing team of AI researchers, engineers, and developers.\",\n",
      "        \"Collaborate cross-functionally with other departments, such as product management, marketing, and business development, to integrate AI capabilities into our products and services.\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"organization\": \"Simplifai\",\n",
      "      \"position\": \"Chief Data Scientist\",\n",
      "      \"duration\": \"May 2018 - Aug 2023 (5 yrs 4 mos)\",\n",
      "      \"location\": \"Oslo (On-site)\",\n",
      "      \"responsibilities\": [\n",
      "        \"Building data products based on deep learning and NLP that helps to automate business processes in various industrial sectors such as Banking, Insurance, etc.\",\n",
      "        \"Architecture of the Data Science pipeline from the research phase to the production environment.\",\n",
      "        \"End-to-End design of Data Science stack.\",\n",
      "        \"Project management, including task and resource planning.\",\n",
      "        \"Research and development of data science projects.\",\n",
      "        \"Integration of APIs with different third-party systems.\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"organization\": \"DNV GL\",\n",
      "      \"position\": \"Data Scientist\",\n",
      "      \"duration\": \"Oct 2016 - May 2018 (1 yr 8 mos)\",\n",
      "      \"location\": \"\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Extract the key sections from the resume above into json.\"\n",
    "\n",
    "answer = resume_qna(doc, prompt, model)\n",
    "print(\"\\033[1;31;34mAnswer:\\n\\n\", answer[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3d74473f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mAnswer:\n",
      "\n",
      " This resume belongs to Bikash Agrawal, a highly experienced professional in AI, Machine Learning, and Big Data solutions. With a Ph.D. in Scalable Data Processing and Analytical Approach for Big Data Cloud Platform, Bikash has a strong background in research and development, project management, and data science. He is currently the Head of Research and Development at Simplifai, where he leads AI initiatives and drives innovation in the field.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "prompt = \"Can you describe this resume in 3 lines?\"\n",
    "\n",
    "answer = resume_qna(doc, prompt, model)\n",
    "print(\"\\033[1;31;34mAnswer:\\n\\n\", answer[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "da05d88b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mAnswer:\n",
      "\n",
      " 1. AI\n",
      "2. Machine Learning\n",
      "3. Big Data\n",
      "4. Research and Development\n",
      "5. Data Scientist\n",
      "6. NLP/LLM\n",
      "7. Data Ingestion Pipeline\n",
      "8. Deep Learning\n",
      "9. Hadoop\n",
      "10. Programming Languages\n"
     ]
    }
   ],
   "source": [
    "prompt = \"What are the 10 keywords of this resume?\"\n",
    "\n",
    "answer = resume_qna(doc, prompt, model)\n",
    "print(\"\\033[1;31;34mAnswer:\\n\\n\", answer[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2fee9d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;34mAnswer:\n",
      "\n",
      " Bikash Agrawal is an experienced AI and Big Data professional with a Ph.D. in Scalable Data Processing and Analytical Approach for Big Data Cloud Platform. He has a strong background in AI research and development, data science, and project management, and is currently the Head of Research and Development at Simplifai.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Summarize this resume in 2 line?\"\n",
    "\n",
    "answer = resume_qna(doc, prompt, model)\n",
    "print(\"\\033[1;31;34mAnswer:\\n\\n\", answer[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8b5a16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445ce222",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
